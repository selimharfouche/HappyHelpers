name: Ransomware Tracker Scraping

on:
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'
  # Allow manual triggering
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # This grants permission to write to the repository
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install Tor
        run: |
          sudo apt-get update
          sudo apt-get install -y tor
          sudo service tor start
          # Verify Tor is running
          sleep 5  # Give Tor time to start
          netstat -tulpn | grep 9050 || echo "Warning: Tor might not be running on port 9050"

      - name: Setup Firefox
        uses: browser-actions/setup-firefox@v1
        with:
          firefox-version: 'latest'

      - name: Install Geckodriver
        run: |
          GECKODRIVER_VERSION=$(curl -s https://api.github.com/repos/mozilla/geckodriver/releases/latest | grep tag_name | cut -d '"' -f 4)
          wget https://github.com/mozilla/geckodriver/releases/download/${GECKODRIVER_VERSION}/geckodriver-${GECKODRIVER_VERSION}-linux64.tar.gz
          tar -xzf geckodriver-${GECKODRIVER_VERSION}-linux64.tar.gz
          sudo mv geckodriver /usr/local/bin/
          geckodriver --version

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # Make sure requests library is installed for process_entities.py
          pip install requests

      - name: Configure for GitHub Actions
        run: |
          # Create temporary GitHub Actions configuration
          mkdir -p /tmp/github_configs/code
          
          # Create scraping_config.json for GitHub Actions (but don't overwrite repo version)
          echo '{
            "snapshots": {
              "save_html": false,
              "max_snapshots_per_site": 5,
              "cleanup_old_snapshots": true
            },
            "scheduling": {
              "frequency_hours": 6,
              "randomize_start_time": true
            }
          }' > /tmp/github_configs/code/scraping_config.json
          
          # Create proxy_config.json for GitHub Actions
          echo '{
            "proxy": {
              "type": "socks",
              "host": "127.0.0.1",
              "port": 9050,
              "remote_dns": true
            },
            "tor": {
              "auto_start": false
            }
          }' > /tmp/github_configs/code/proxy_config.json
          
          # Create browser_config.json with Firefox binary path
          echo '{
            "timing": {
              "min_wait_time": 10,
              "max_wait_time": 20,
              "tor_check_wait_time": 3,
              "page_load_timeout": 120
            },
            "anti_bot": {
              "enabled": true,
              "randomize_timing": true
            },
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; rv:102.0) Gecko/20100101 Firefox/102.0",
            "firefox_binary": "'$(which firefox)'"
          }' > /tmp/github_configs/code/browser_config.json
          
          # Print Firefox and Geckodriver information for debugging
          echo "Firefox path: $(which firefox)"
          firefox --version
          echo "Geckodriver path: $(which geckodriver)"
          geckodriver --version

      - name: Run scraper
        run: |
          # Create necessary directories
          mkdir -p data/output
          mkdir -p data/html_snapshots
          mkdir -p data/processed
          
          # Export environment variable to point to temporary config
          export GITHUB_CONFIG_PATH="/tmp/github_configs"
          
          # Run the scraper with verbose output
          cd tracker
          python main.py

      - name: Process and archive entities
        run: |
          # Run the entity processing script to standardize and archive entities
          cd tracker/processing
          python process_entities.py
          echo "Entity processing and archiving completed"

      - name: Commit and push if there are changes
        run: |
          # Clean up geckodriver tarball
          rm -f geckodriver-*.tar.gz
          
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Only commit changes to data directory, not config
          git add -A data/
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Auto-update data from scheduled scrape"
            git push
          fi